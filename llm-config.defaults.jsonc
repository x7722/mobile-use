// Here is the default config that will be used if no override is provided.
{
  "default": {
    "planner": {
      "provider": "openai",
      "model": "gpt-5-nano",
      "fallback": {
        "provider": "openai",
        "model": "gpt-5-mini"
      }
    },
    "orchestrator": {
      "provider": "openai",
      "model": "gpt-5-nano",
      "fallback": {
        "provider": "openai",
        "model": "gpt-5-mini"
      }
    },
    "cortex": {
      "provider": "openai",
      "model": "gpt-5",
      "fallback": {
        "provider": "openai",
        "model": "o4-mini"
      }
    },
    "executor": {
      "provider": "openai",
      "model": "gpt-5-nano",
      "fallback": {
        "provider": "openai",
        "model": "gpt-5-mini"
      }
    },
    "contextor": {
      "provider": "openai",
      "model": "gpt-5-nano",
      "fallback": {
        "provider": "openai",
        "model": "gpt-5-mini"
      }
    },
    "utils": {
      "hopper": {
        // Needs at least a 256k context window.
        "provider": "openai",
        "model": "gpt-5-nano",
        "fallback": {
          "provider": "openai",
          "model": "gpt-5-mini"
        }
      },
      "outputter": {
        "provider": "openai",
        "model": "gpt-5-nano",
        "fallback": {
          "provider": "openai",
          "model": "gpt-5-mini"
        }
      }
    }
  },
  // This is the config we recommend.
  // To use it, copy it to llm.override.jsonc, following llm.override.template.jsonc.
  "recommended": {
    "planner": {
      "provider": "minitap",
      "model": "meta-llama/llama-4-scout",
      "fallback": {
        "provider": "minitap",
        "model": "meta-llama/llama-4-maverick"
      }
    },
    "orchestrator": {
      "provider": "minitap",
      "model": "openai/gpt-oss-120b",
      "fallback": {
        "provider": "minitap",
        "model": "meta-llama/llama-4-maverick"
      }
    },
    "cortex": {
      "provider": "minitap",
      "model": "google/gemini-2.5-pro",
      "fallback": {
        "provider": "minitap",
        "model": "openai/gpt-5"
      }
    },
    "executor": {
      "provider": "minitap",
      "model": "meta-llama/llama-3.1-70b-instruct",
      "fallback": {
        "provider": "minitap",
        "model": "openai/gpt-5-mini"
      }
    },
    "contextor": {
      "provider": "minitap",
      "model": "meta-llama/llama-3.1-8b-instruct",
      "fallback": {
        "provider": "minitap",
        "model": "meta-llama/llama-3.3-70b-instruct"
      }
    },
    "utils": {
      "hopper": {
        // Needs at least a 256k context window.
        "provider": "minitap",
        "model": "openai/gpt-5-nano",
        "fallback": {
          "provider": "minitap",
          "model": "openai/gpt-5-mini"
        }
      },
      "outputter": {
        "provider": "minitap",
        "model": "openai/gpt-5-nano",
        "fallback": {
          "provider": "minitap",
          "model": "openai/gpt-5-mini"
        }
      }
    }
  }
}
